{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Running Inference on Habana Gaudi (HPU)\n",
                "\n",
                "This notebook demonstrates how to run inference using the Habana Gaudi processor (HPU) with our GPT model for classification task from Chapter 6."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Construct model (same as in Chapter 6)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import necessary libraries\n",
                "import habana_frameworks.torch # import Habana PyTorch framework first\n",
                "import torch\n",
                "import tiktoken"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# initialize tokenizer\n",
                "tokenizer = tiktoken.get_encoding(\"gpt2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model configuration and parameters\n",
                "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
                "INPUT_PROMPT = \"Every effort moves\"\n",
                "\n",
                "BASE_CONFIG = {\n",
                "    \"vocab_size\": 50257,     # Vocabulary size\n",
                "    \"context_length\": 1024,  # Context length\n",
                "    \"drop_rate\": 0.0,        # Dropout rate\n",
                "    \"qkv_bias\": True         # Query-key-value bias\n",
                "}\n",
                "\n",
                "model_configs = {\n",
                "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
                "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
                "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
                "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
                "}\n",
                "\n",
                "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# use functions from previous chapters to download and load the model\n",
                "from gpt_download import download_and_load_gpt2\n",
                "from previous_chapters import GPTModel, load_weights_into_gpt\n",
                "\n",
                "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
                "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
                "\n",
                "model = GPTModel(BASE_CONFIG)\n",
                "load_weights_into_gpt(model, params)\n",
                "\n",
                "# add a new output head to the model (same as in Chapter 6)\n",
                "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load model weights\n",
                "We use the weights saved when we trained the model in Chapter 6 on spam classification task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_state_dict = torch.load(\"review_classifier.pth\", map_location=torch.device(\"cpu\"), weights_only=True) # load weights to CPU to avoid memory issues\n",
                "model.load_state_dict(model_state_dict) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Move model to HPU\n",
                "You have to have access to HPU!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"hpu\")\n",
                "model.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Classify reviews function\n",
                "Same as in Chapter 6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
                "    model.eval()\n",
                "\n",
                "    # Prepare inputs to the model\n",
                "    input_ids = tokenizer.encode(text)\n",
                "    supported_context_length = model.pos_emb.weight.shape[0]\n",
                "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
                "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
                "\n",
                "    # Truncate sequences if they too long\n",
                "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
                "\n",
                "    # Pad sequences to the longest sequence\n",
                "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
                "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
                "\n",
                "    # Model inference\n",
                "    with torch.no_grad():\n",
                "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
                "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
                "\n",
                "    # Return the classified result\n",
                "    return \"spam\" if predicted_label == 1 else \"not spam\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Test the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text_1 = (\n",
                "    \"You are a winner you have been specially\"\n",
                "    \" selected to receive $1000 cash or a $2000 award.\"\n",
                ")\n",
                "\n",
                "print(classify_review(\n",
                "    text_1, model, tokenizer, device, max_length=120\n",
                "))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "text_2 = (\n",
                "    \"Hey, just wanted to check if we're still on\"\n",
                "    \" for dinner tonight? Let me know!\"\n",
                ")\n",
                "\n",
                "print(classify_review(\n",
                "    text_2, model, tokenizer, device, max_length=120\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It works!\n",
                "Now let's compare the performance of the model on CPU and HPU."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Performance comparison\n",
                "We will use the `time` library to measure the time it takes to classify a review."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Let's create a couple of spam/not spam messages\n",
                "messages = [\n",
                "    \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\", # Spam\n",
                "    \"Please send me your bank details so I can transfer you the money.\", # Spam\n",
                "    \"I'm going to the gym now, want to join?\", # Not spam\n",
                "    \"This is not spam, it's a test message.\", # Not spam\n",
                "    \"Congratulations! You've won a free iPhone! Click here to claim.\", # Spam\n",
                "    \"Hey, are we still on for lunch tomorrow?\",  # Not spam\n",
                "    \"URGENT! Your account has been compromised. Reset your password now!\",  # Spam\n",
                "    \"Meeting rescheduled to 3 PM. Let me know if that works.\",  # Not spam\n",
                "    \"Limited time offer! Buy now and get 50% off!\",  # Spam\n",
                "    \"Can you review this document and send me your feedback?\",  # Not spam\n",
                "    \"FREE MONEY! Click this link to receive your reward.\",  # Spam\n",
                "    \"Your order has been shipped. Track it here.\",  # Not spam\n",
                "    \"Earn $$$ from home! No experience needed. Sign up today.\",  # Spam\n",
                "    \"Reminder: Your dentist appointment is on Monday at 10 AM.\",  # Not spam\n",
                "    \"Exclusive deal just for you! Unlock your discount now!\",  # Spam\n",
                "    \"Happy Birthday! Hope you have an amazing day!\",  # Not spam\n",
                "    \"Claim your prize before it's too late! Act now!\",  # Spam\n",
                "    \"Thanks for your help with the project. Appreciate it!\",  # Not spam\n",
                "    \"Your PayP@l account needs verification! Click here immediately!\",  # Spam\n",
                "    \"Hey, can you send me that report by EOD?\",  # Not spam\n",
                "    \"Final warning! Your subscription will be canceled unless you act now!\",  # Spam\n",
                "    \"Dinner plans tonight? Let me know.\",  # Not spam\n",
                "    \"You have been selected for a special offer! Open now!\",  # Spam\n",
                "    \"Let's catch up over coffee next week.\",  # Not spam\n",
                "    \"Instant weight loss! See the miracle solution here.\",  # Spam\n",
                "    \"Just checking in—how are you doing?\",  # Not spam\n",
                "    \"Hurry! Stocks are running out. Order yours today!\",  # Spam\n",
                "    \"Can you confirm the schedule for tomorrow?\",  # Not spam\n",
                "    \"Dear user, your acc0unt has suspicious activity. Verify now!\",  # Spam\n",
                "    \"Great job on the presentation today!\",  # Not spam\n",
                "    \"Double your profits in just 7 days! Guaranteed!\",  # Spam\n",
                "    \"I'll be late for the meeting, stuck in traffic.\",  # Not spam\n",
                "    \"Secret investment opportunity—make millions fast!\",  # Spam\n",
                "    \"Let's finalize the contract details this afternoon.\",  # Not spam\n",
                "    \"Congratulations, you are the chosen winner of our lottery!\",  # Spam\n",
                "    \"Thanks for your help with the budget analysis.\",  # Not spam\n",
                "    \"Y0ur p@ckage is d3layed. Cl!ck here to f!x.\",  # Spam\n",
                "    \"I’ll send over the revised slides shortly.\",  # Not spam\n",
                "    \"Work from home and make $$$ instantly!\",  # Spam\n",
                "    \"Can you join the call at 2 PM instead of 3?\",  # Not spam\n",
                "    \"Limited seats available! Enroll in our exclusive program today.\",  # Spam\n",
                "    \"See you at the event later!\",  # Not spam\n",
                "    \"Hurry! This deal won’t last long. Act fast!\",  # Spam\n",
                "    \"Your invoice for last month is attached.\",  # Not spam\n",
                "    \"Boost your credit score instantly! Click here.\",  # Spam\n",
                "    \"Looking forward to our meeting tomorrow.\",  # Not spam\n",
                "    \"Your social media account has been hacked! Reset password now!\",  # Spam\n",
                "    \"Let’s schedule a team lunch next week.\",  # Not spam\n",
                "    \"Easy way to make extra cash online—start today!\",  # Spam\n",
                "    \"Can you review the proposal before we submit?\",  # Not spam\n",
                "    \"F!nal rem!nder: Update y0ur b@nk details NOW!\",  # Spam\n",
                "    \"Thanks for the update on the project.\",  # Not spam\n",
                "    \"Your subscription has been successfully renewed.\",  # Not spam\n",
                "    \"Meet singles in your area now!\",  # Spam\n",
                "    \"I left my laptop at the office, can you bring it?\",  # Not spam\n",
                "    \"You are pre-approved for a low-interest loan!\",  # Spam\n",
                "    \"Looking forward to your presentation next week!\",  # Not spam\n",
                "    \"WIN a brand-new car! Just sign up!\",  # Spam\n",
                "    \"Hope you’re feeling better today!\",  # Not spam\n",
                "    \"Act fast! This offer expires soon!\",  # Spam\n",
                "    \"Thanks for the great conversation earlier.\",  # Not spam\n",
                "    \"Your p@ssw0rd will expire soon! Cl!ck here to reset.\",  # Spam\n",
                "    \"Don’t forget our dinner plans tonight!\",  # Not spam\n",
                "    \"Limited-time deal! Get yours now before it’s gone!\",  # Spam\n",
                "    \"Have a safe flight!\",  # Not spam\n",
                "    \"FREE investment tips! Join our webinar today!\",  # Spam\n",
                "    \"Let me know if you need any help with the project.\",  # Not spam\n",
                "    \"This is not a scam! You have won $1,000,000!\",  # Spam\n",
                "    \"Excited to see you at the conference!\",  # Not spam\n",
                "    \"You won’t believe this shocking weight loss secret!\",  # Spam\n",
                "    \"Are you available for a quick call?\",  # Not spam\n",
                "    \"Act n0w! Your acc0unt has been compromised!\",  # Spam\n",
                "    \"Let’s meet at the usual coffee shop.\",  # Not spam\n",
                "    \"Earn p@ssive inc0me with this one simple trick!\",  # Spam\n",
                "    \"Thanks for helping me with the move.\",  # Not spam\n",
                "    \"Your cl@im has been approved! Cl!ck here to get it.\",  # Spam\n",
                "    \"Don’t miss out on this exclusive deal!\",  # Spam\n",
                "    \"Let’s touch base later today.\",  # Not spam\n",
                "    \"This is your last chance to claim your reward!\",  # Spam\n",
                "    \"Great catching up with you yesterday!\",  # Not spam\n",
                "    \"Cl@im y0ur refund now! L!mited time offer!\",  # Spam\n",
                "    \"Important update regarding your bank account.\",  # Spam\n",
                "    \"See you at the meeting in 10 minutes.\",  # Not spam\n",
                "    \"Get rich quick with this foolproof method!\",  # Spam\n",
                "    \"I’ll send you the details by email.\",  # Not spam\n",
                "    \"Unbelievable investment opportunity—act now!\",  # Spam\n",
                "    \"Don’t forget about the deadline tomorrow.\",  # Not spam\n",
                "    \"Y0ur Netflix account is locked! Verify now!\",  # Spam\n",
                "    \"Grab your free sample today!\",  # Spam\n",
                "    \"I’ll share the report with you later.\",  # Not spam\n",
                "    \"This stock is about to skyrocket! Invest today!\",  # Spam\n",
                "    \"Reminder: Submit your expense report by Friday.\",  # Not spam\n",
                "    \"Claim your Bitcoin bonus now!\",  # Spam\n",
                "    \"XXX WEBSITE XXX\", # Spam\n",
                "    ]\n",
                "\n",
                "num_messages = len(messages)\n",
                "\n",
                "# Test on CPU\n",
                "start_time = time.time()\n",
                "cpu_results = [classify_review(msg, model, tokenizer, device, max_length=120) for msg in messages]\n",
                "end_time = time.time()\n",
                "cpu_time = end_time - start_time\n",
                "print(f\"CPU time: {cpu_time:.2f / num_messages} seconds per message\")\n",
                "\n",
                "# Test on HPU\n",
                "start_time = time.time()\n",
                "hpu_results = [classify_review(msg, model, tokenizer, device, max_length=120) for msg in messages]\n",
                "end_time = time.time()\n",
                "hpu_time = end_time - start_time\n",
                "print(f\"HPU time: {hpu_time:.2f / num_messages} seconds per message\")\n",
                "\n",
                "# Compare results\n",
                "print(f\"HPU faster by {cpu_time / hpu_time:.2f}x\")"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
